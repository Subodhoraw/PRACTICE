{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea081195",
   "metadata": {},
   "source": [
    "Reverse a List Without Using Reverse()\n",
    "\n",
    "Input:\n",
    "\n",
    "nums = [1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e3e7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "nums = [1,2,3,4,5]\n",
    "print(nums[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727010bb",
   "metadata": {},
   "source": [
    "2️⃣ Count Frequency of Each Word in a Sentence\n",
    "\n",
    "Input:\n",
    "\"ai is the future and ai will lead the future\"\n",
    "\n",
    "Expected output:\n",
    "\n",
    "{'ai': 2, 'is': 1, 'the': 2, 'future': 2, 'and': 1, 'will': 1, 'lead': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa89524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ai': 2, 'is': 1, 'the': 2, 'future': 2, 'and': 1, 'will': 1, 'lead': 1}\n"
     ]
    }
   ],
   "source": [
    "sent = \"ai is the future and ai will lead the future\"\n",
    "#clean and split\n",
    "words = sent.lower().split()\n",
    "\n",
    "frequency = {}\n",
    "for word in words:\n",
    "    if word in frequency:\n",
    "        frequency[word] += 1\n",
    "    else : \n",
    "        frequency[word] =1\n",
    "print(frequency)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f3c8fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai        2\n",
      "the       2\n",
      "future    2\n",
      "is        1\n",
      "and       1\n",
      "will      1\n",
      "lead      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sent = \"ai is the future and ai will lead the future\"\n",
    "words = sent.lower().replace(',' ,'').split()\n",
    "series = pd.Series(words)\n",
    "\n",
    "# count values \n",
    "counts = series.value_counts()\n",
    "\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f02561ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1, 2: 2, 3: 2, 4: 2, 5: 1, 6: 2, 7: 2, 8: 1, 91: 1, 9: 1}\n"
     ]
    }
   ],
   "source": [
    "nums = [1,2,3,4,5,6,7,8,91,2,3,4,6,7,9]\n",
    "frequency = {} #make sure it should be a container \n",
    "\n",
    "for num in nums:\n",
    "    if num in frequency:\n",
    "        frequency[num] += 1\n",
    "    else:\n",
    "        frequency[num] = 1\n",
    "\n",
    "print(frequency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810baed8",
   "metadata": {},
   "source": [
    "Remove Duplicates Without Using Set\n",
    "\n",
    "Input:\n",
    "\n",
    "[1, 2, 2, 3, 4, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e75dd2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5}\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 91]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 91, 9]\n"
     ]
    }
   ],
   "source": [
    "num = [1, 2, 2, 3, 4, 4, 5]\n",
    "num1 = set(num)\n",
    "print(num1)\n",
    "nums = [1, 2, 3, 4, 5, 6, 7, 8, 91, 2, 3, 4, 6, 7, 9]\n",
    "num1 = list(set(nums))\n",
    "print(num1)\n",
    "\n",
    "#lets make it without even its original sequances \n",
    "num1 = list(dict.fromkeys(nums)) \n",
    "print(num1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5084ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 91, 9]\n"
     ]
    }
   ],
   "source": [
    "unique = []\n",
    "for num in nums:\n",
    "    if num not in unique:\n",
    "        unique.append(num)\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc470193",
   "metadata": {},
   "source": [
    "4️⃣ Find Second Largest Number Without Sorting\n",
    "\n",
    "Input:\n",
    "\n",
    "[90, 12, 45, 87, 23]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "736d1a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "num = [90, 12, 45, 87, 23]\n",
    "print(num[-2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe8ccd",
   "metadata": {},
   "source": [
    "if we have n number, how to find the largest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "357fd597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "nums = [12, 45, 2, 41, 31, 10, 8, 6, 45]\n",
    "largest = heapq.nlargest(3,set(nums))\n",
    "print(largest[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83964286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest :45\n"
     ]
    }
   ],
   "source": [
    "nums = [12, 45, 2, 41, 31, 10, 8, 6, 45]\n",
    "def secndlargest(nums):\n",
    "  largest = float('-inf')\n",
    "  second_largest = float('-inf')\n",
    "  for num in nums:\n",
    "    if num > largest:\n",
    "      second_largest = largest\n",
    "      largest = num \n",
    "    elif num > second_largest and num != largest:\n",
    "      # logic to second largest only\n",
    "      second_largest = num \n",
    "  return largest, second_largest\n",
    "\n",
    "\n",
    "largest, second_largest = secndlargest(nums)\n",
    "print(f\"Largest :{largest}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "197d0852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest: 99\n",
      "Second Largest: 45\n"
     ]
    }
   ],
   "source": [
    "nums = [10, 20, 4, 45, 99, 45, 99]\n",
    "\n",
    "# Initialize with negative infinity so any number is larger\n",
    "largest = float('-inf')\n",
    "second_largest = float('-inf')\n",
    "\n",
    "for num in nums:\n",
    "    if num > largest:\n",
    "        # Current largest becomes second; new num becomes largest\n",
    "        second_largest = largest\n",
    "        largest = num\n",
    "    elif num > second_largest and num != largest:\n",
    "        # Logic to update second largest only\n",
    "        second_largest = num\n",
    "\n",
    "print(f\"Largest: {largest}\")\n",
    "print(f\"Second Largest: {second_largest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196dbce7",
   "metadata": {},
   "source": [
    "5️⃣ Convert a Nested Dict to Single Dictionary\n",
    "\n",
    "Input:\n",
    "\n",
    "{\"a\":1, \"b\":{\"c\":2, \"d\":3}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7891c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b0c  b0d\n",
      "0  1    2    3\n",
      "{'a': 1, 'b0c': 2, 'b0d': 3}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = {\"a\":1, \"b\":{\"c\":2, \"d\":3}}\n",
    "df = pd.json_normalize(data, sep ='0')\n",
    "print(df)\n",
    "\n",
    "#convert back to dictionary(optional, if you dont want a dtaframe)\n",
    "flat_dict = df.to_dict(orient = 'records')[0]\n",
    "\n",
    "print(flat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73f0b58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'c': 2, 'd': 3}\n"
     ]
    }
   ],
   "source": [
    "def flatten_dict_drop_parents(d):\n",
    "    new_dict ={}\n",
    "    for key , value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            #if value is a dict, dig deeper(recursion)\n",
    "            # then merge that result into our main dict\n",
    "            child_dict = flatten_dict_drop_parents(value)\n",
    "            new_dict.update(child_dict)\n",
    "        else: \n",
    "            # if its normal value then kepp as it is \n",
    "            new_dict[key] = value\n",
    "    return new_dict\n",
    "#input\n",
    "nested_data = {\"a\": 1, \"b\": {\"c\": 2, \"d\": 3}}\n",
    "\n",
    "# ----output----\n",
    "flat_data = flatten_dict_drop_parents(nested_data)\n",
    "\n",
    "print(flat_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f599ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict_drop_parents(d):\n",
    "    new_dict= {}\n",
    "    for key , value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            # if value is a dict, dig deeper(recursion)\n",
    "            child_dict = flatten_dict_drop_parents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44323273",
   "metadata": {},
   "source": [
    "Read a JSON file and print all keys\n",
    "\n",
    "Given a JSON like:\n",
    "\n",
    "{ \"Name\":\"John\", \"Age\":25, \"City\":\"Delhi\" }\n",
    "\n",
    "\n",
    "Print:\n",
    "\n",
    "Name, Age, City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aa3c93",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 189)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m \n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mtitanic.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding = \u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m, errors = \u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m :\n\u001b[32m      6\u001b[39m     data = json.loads(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\decoder.py:348\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    346\u001b[39m end = _w(s, end).end()\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExtra data\u001b[39m\u001b[33m\"\u001b[39m, s, end)\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Extra data: line 2 column 1 (char 189)"
     ]
    }
   ],
   "source": [
    "import json \n",
    "with open('titanic.json', 'r', encoding = 'utf-8', errors = 'ignore') as file:\n",
    "    data = json.load(file)\n",
    "     try :\n",
    "    data = json.loads(data)\n",
    "   except json.JSONDecodeError:\n",
    "        print(\"Standard JSON failed. Trying python eval...\")\n",
    "        # fallback : parse as python dictionary syntax \n",
    "# get the keys\n",
    "keys = data.keys()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e72a2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard JSON failed. Trying Python eval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\/'\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 2)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  Cell \u001b[92mIn[37]\u001b[39m\u001b[92m, line 10\u001b[39m\n    data = json.loads(content)\n",
      "  File \u001b[92mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\__init__.py:346\u001b[39m in \u001b[95mloads\u001b[39m\n    return _default_decoder.decode(s)\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\decoder.py:348\u001b[39m\u001b[36m in \u001b[39m\u001b[35mdecode\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mraise JSONDecodeError(\"Extra data\", s, end)\u001b[39m\n",
      "\u001b[31mJSONDecodeError\u001b[39m\u001b[31m:\u001b[39m Extra data: line 2 column 1 (char 189)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:3699\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[37]\u001b[39m\u001b[92m, line 14\u001b[39m\n    data = ast.literal_eval(content)\n",
      "  File \u001b[92mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ast.py:68\u001b[39m in \u001b[95mliteral_eval\u001b[39m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ast.py:54\u001b[39m\u001b[36m in \u001b[39m\u001b[35mparse\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn compile(source, filename, mode, flags,\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m<unknown>:2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m{\"PassengerId\":\"2\",\"Survived\":\"1\",\"Pclass\":\"1\",\"Name\":\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",\"Sex\":\"female\",\"Age\":38,\"SibSp\":\"1\",\"Parch\":\"0\",\"Ticket\":\"PC 17599\",\"Fare\":71.2833,\"Cabin\":\"C85\",\"Embarked\":\"C\"}\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ast # Abstract Syntax Tree\n",
    "\n",
    "# If your file looks like: {'Name': 'John'} (Single quotes)\n",
    "with open('titanic.json', 'r') as file:\n",
    "    content = file.read()\n",
    "    \n",
    "    try:\n",
    "        # Try standard JSON first\n",
    "        data = json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Standard JSON failed. Trying Python eval...\")\n",
    "        # Fallback: Parse as Python dictionary syntax\n",
    "        data = ast.literal_eval(content)\n",
    "\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970502ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd e:\\bugshere\\PRACTICE\\python recap\n",
      "files before  ['recap.ipynb', 'sample3.json', 'titanic.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1. show current working dir (should match what you pasted )\n",
    "print( \"cwd\", os.getcwd())\n",
    "\n",
    "# 2. list files in that dir\n",
    "print( \"files before \", os.listdir(os.getcwd()))\n",
    "\n",
    "#3.c\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
